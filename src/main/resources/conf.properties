#############################
# kafka配置
#############################
#kafka common
kafka.bootstrap.servers=localhost:9092
# Kafka Consumer
kafka.group.id=test-group-
kafka.key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
kafka.value.deserializer=org.apache.kafka.common.serialization.StringDeserializer
kafka.heartbeat.interval.ms=5000
kafka.session.timeout.ms=10000
kafka.enable.auto.commit=true
kafka.auto.commit.interval.ms=10000
kafka.auto.offset.reset=earliest
#kafka.auto.offset.reset=latest
kafka.connections.max.idle.ms=540000
kafka.max.poll.records=10

#测试topic
kafka.kks.topic=s003-01-rt-dealed-

#kafka.client.id=id1
# Kafka Producer
# ack方式，all，会等所有的commit最慢的方式
kafka.acks=1
# 客户端如果发送失败则会重新发送
kafka.retries=5

# 默认立即发送，这里这是延时毫秒数
kafka.linger.ms=10
# producer会阻塞max.block.ms，超时则抛出异常,此处设为3m
kafka.max.block.ms=3
#Producer可以用来缓存数据的内存大小。该值实际为RecordAccumulator类中的BufferPool，
#即Producer所管理的最大内存。如果数据产生速度大于向broker发送的速度，
kafka.buffer.memory=31457280
#Producer用于压缩数据的压缩类型，取值：none, gzip, snappy, or lz4
kafka.compression.type=snappy
# 当多个消息要发送到相同分区的时，生产者尝试将消息批量打包在一起，以减少请求交互
#Producer可以将发往同一个Partition的数据做成一个Produce Request发送请求，
# 即Batch批处理，以减少请求次数，该值即为每次批处理的大小。
#另外每个Request请求包含多个Batch，每个Batch对应一个Partition，
#且一个Request发送的目的Broker均为这些partition的leader副本。
#若将该值设为0，则不会进行批处理,此处设为1m
kafka.batch.size=1048576
kafka.maxRatePerPartition=10
kafka.send.buffer.bytes=131072
#请求的最大字节数。这也是对最大消息大小的有效限制。注意：server具有自己对消息大小的限制，
#这些大小和这个设置不同。此项设置将会限制producer每次批量发送请求的数目，以防发出巨量的请求。
#此处设置为3m
kafka.max.request.size=31457280
